---
title: "mag_processing"
output: html_document
date: '2025-05-21'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggimage)
library(gtools)

summarize = dplyr::summarize
```


## Tsimane Metagenomics QC 

### Raw read processing

```{r }
table_parse = function(path) {
  sample_id = strsplit(basename(path), '__')[[1]][1]
  return(fread(path, sep='\t') %>% mutate(sample_id = sample_id))
}

## These are files made during our metagenomics "pre-processing" pipeline that summarises 
## read and base counts.
qc_summary_file_path = '/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/qc_summaries/'
files <- list.files(path = qc_summary_file_path, pattern = ".txt")

qc_summary_df <- lapply(paste0(qc_summary_file_path, files), table_parse) %>% 
  rbindlist() %>%
  arrange(desc(unique_bases)) %>%
  mutate(sample_type = 'ADULT')

# Total RAW bases
(qc_summary_df %>% pull(raw_bases) %>% sum())/1e9
# Total RAW reads
(qc_summary_df %>% pull(raw_reads) %>% sum())/1e9

# Plot distribtion of raw bases
ggplot(qc_summary_df, aes(raw_bases / 1e9)) +
  geom_histogram() +
  theme_bw() + 
  facet_wrap(~sample_type, scales='free_x') +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  ylab('Count') +
  xlab('RAW Gbp') +
  geom_vline(xintercept=c(10, 25))


# Total PROCESSED bases
(qc_summary_df %>% pull(unique_bases) %>% sum())/1e9
# Total PROCESSED reads
(qc_summary_df %>% pull(unique_reads) %>% sum())/1e9

# Median depth per sample (processed bases)
(qc_summary_df %>% pull(unique_bases) %>% median())/1e9

# Plot distribution of processed bases
ggplot(qc_summary_df, aes(unique_bases / 1e9)) +
  geom_histogram(binwidth=2) +
  theme_bw() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  ylab('Count') +
  xlab('UNIQUE Gbp') 


# Make data frame and plot of bases removed during processing 
qc_summary_df_fractions = qc_summary_df %>%
  rowwise() %>%
  mutate(duplicate_loss = duplicate_bases / raw_bases,
         host_loss = host_reads / raw_reads,
         trimming_loss = 1-trimmed_bases / raw_bases) %>%
  select(SampleName, sample_type, duplicate_loss, host_loss, trimming_loss) %>%
  gather(key='variable', value='fraction', -SampleName, -sample_type)

ggplot(qc_summary_df_fractions, aes(x=fraction * 100, y=variable)) +
  geom_boxplot() +
  theme_bw() +
  facet_wrap(~sample_type) + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  ylab('Variable') +
  xlab('Percent reads removed')  

(qc_summary_df %>% filter(SampleName %in% tsimane_samples_included) %>% pull(raw_bases) %>% sum())/1e9
```

### Assembly processing

```{r }
quast_table_parse = function(path) {
  sample_id = tools::file_path_sans_ext(strsplit(basename(path), '__')[[1]][2])
  quast_log = fread(path, sep='\t') %>% mutate(sample_id = sample_id) %>%
    select(1,2) %>%
    dplyr::rename(value = 2) %>%
    mutate(sample_id = sample_id) %>%
    spread(key='Assembly', value='value')
  return(quast_log)
}

## These files are assembly QC summaries generated by QUAST
quast_logs_file_path = '/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/quast_summaries/'
quast_files <- list.files(path = quast_logs_file_path, pattern = ".tsv")
quast_summary_df <- lapply(paste0(quast_logs_file_path, quast_files), quast_table_parse) %>% 
  rbindlist() %>%
  mutate(sample_type = 'ADULT')

# QC plots for number of contigs and N50 distribution
ggplot(quast_summary_df, aes(x=`# contigs (>= 1500 bp)`)) +
  geom_histogram() +
  facet_wrap(~sample_type, scales='free_x')

ggplot(quast_summary_df, aes(x=`N50`)) +
  geom_histogram() +
  facet_wrap(~sample_type, scales='free_x')

# Median N50 contig length
quast_summary_df %>% summarise(median(N50))

# Total length of all contigs in all assemblies
(quast_summary_df %>% filter(sample_id %in% tsimane_samples_included) %>% summarise(sum(`Total length`)))/1e9
```

### Bin processing

```{r checkm_stats}
checkm_table_parse = function(path) {
  sample_id = tools::file_path_sans_ext(strsplit(basename(path), '__')[[1]][2])
  checkm_log = fread(path, sep='\t') %>% mutate(sample_id = sample_id) %>%
    mutate(sample_id = sample_id) %>%
    mutate(sample_type = 'ADULT')
  return(checkm_log)
}

# These are bin quality files generated by CheckM 
checkm_logs_file_path = '/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/checkm_summaries/'
checkm_files <- list.files(path = checkm_logs_file_path, pattern = ".txt")
checkm_summary_df <- lapply(paste0(checkm_logs_file_path, checkm_files), checkm_table_parse) %>% 
  rbindlist() %>%
  filter(Completeness >= 50 & Contamination <= 10) %>%
  mutate(bin_quality = ifelse(Completeness > 90 & Contamination < 5, 'HQ', 'MQ'))

# Total number of bins per sample by quality type
checkm_summary_df %>%
  group_by(bin_quality) %>%
  dplyr::summarize(num_genomes = n())

# Distribution of bins per sample, by bin quality category
# ggplot(checkm_by_sample, aes(x=num_genomes)) +
#   geom_histogram() +
#   facet_wrap(~bin_quality, scales='free_x')
checkm_summary_df %>% filter(sample_id %in% tsimane_samples_included)
```

### GTDB processing

```{r read_gtdb_results}
## Results of running all bins from all studies below through GTDB
combined_gtdb_results = read_tsv(file = '/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/GTDB_results/combined_gtdb_r220_results.tsv')

```

## Load study genome meta

### UHGG (Industrial cohorts)

```{r uhgg_metas}

# SRP002163 = North America = HMP (HMP, 2012, Nature)
# ERP004605 = Europe =  Gene catalog paper, Denmark and Spain (Li, et al., 2014, Nature Biotech)
# SRP008047 = Asia = Chinese cohort (Qin, 2012, Nature)

uhgg_meta = read_csv("/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/genome_database/Carter2023_genome_database.csv") %>%
  filter(substudy == 'SRP002163' | substudy == 'ERP004605' | substudy == 'SRP008047') %>% 
  mutate(study = case_when(
    substudy == 'SRP002163' ~ 'NorthAmerica',
    substudy == 'ERP004605' ~ 'Europe',
    substudy == 'SRP008047' ~ 'Asia'
  )) %>%
  select(genome, study, sample, Completeness, Contamination, Length, N50, N_contigs) %>% 
  dplyr::rename(sample_id = 3) %>%
  rowwise() %>%
  mutate(genome = str_replace(genome, '.fna', ''),
         SUBJECT_ID = sample_id)

```

### Hadza

```{r Hadza + Nepal meta}

hadza_basic_info = read.csv('/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/meta_data/Hadza_basic_info.csv')

## INCLUDES NEPAL SAMPLES
hadza_meta = read_csv("/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/genome_database/Carter2023_genome_database.csv") %>% 
  filter(substudy == 'HADZA') %>%
  select(genome, substudy, sample, Completeness, Contamination, Length, N50, N_contigs) %>%
  dplyr::rename(study = 2, sample_id = 3) %>%
  rowwise() %>%
  mutate(genome = str_replace(genome, '.fa', ''),
         study = case_when(
           TRUE ~ 'Hadza'
         )) %>% 
  left_join(hadza_basic_info, by=c('sample_id'='SampleName')) %>%
  mutate(SUBJECT_ID = ifelse(is.na(SUBJECT_ID), sample_id, SUBJECT_ID)) %>%
  select(genome, study, SUBJECT_ID, sample_id, Completeness, Contamination, Length, N50, N_contigs)


# Number of unique individuals in Hadza cohort (adults only)
hadza_meta %>% 
  filter(study == 'Hadza') %>% pull(SUBJECT_ID) %>% unique() %>% length()

```


### Tsimane

```{r tsimane_meta}
tsimane_basic_info = read.csv('/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/meta_data/Tsimane_basic_info.csv') 


binstat_parse = function(path) {
  sample = strsplit(strsplit(basename(path), '\\.binstats')[[1]][1], '__')[[1]][2]
  return(fread(path, sep='\t') %>% mutate(sample_id = sample))
}

## Load data about bin statistics from running METABAT on Tsimane data
tsimane_binstats_path = '/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/metabat_summaries_tsimane/'
binstats_files <- list.files(path = tsimane_binstats_path, pattern = ".txt")
tsimane_binstats_df <- lapply(paste0(tsimane_binstats_path, binstats_files), binstat_parse) %>%
  rbindlist(fill = TRUE) %>%
  rowwise() %>% 
  mutate(genome = str_replace(basename(filename), '.fa', '')) %>%
  select(genome, contig_bp, ctg_L50, n_contigs) %>%
  dplyr::rename(Length = contig_bp, N50 = ctg_L50, N_contigs = n_contigs)

## Start with `checkm_summary_df` generated above
tsimane_meta = checkm_summary_df %>%
  mutate(study = 'Tsimane') %>%
  filter(grepl('ADULT', sample_id)) %>%
  dplyr::rename(genome = 1) %>%
  left_join(tsimane_binstats_df, by='genome') %>%
  rowwise() %>%
  select(genome, study, sample_id, Completeness, Contamination, Length, N50, N_contigs) %>%
  left_join(tsimane_basic_info, by='sample_id') %>%
  filter(Age_Years >= 3.0) %>%
  filter(!is.na(Subject_ID)) %>%
  dplyr::rename(SUBJECT_ID = Subject_ID) %>%
  select(genome, study, SUBJECT_ID, sample_id, Completeness, Contamination, Length, N50, N_contigs)

# Number of unique individuals in Tsimane cohort
tsimane_meta %>% 
  pull(SUBJECT_ID) %>% unique() %>% length()


tsimane_samples_included = tsimane_meta %>% pull(sample_id) %>% unique()

sprockett_tsimane_ps = readRDS('/home/mmcarter/user_data/scripts/211102_tsimane_samples/Sprockett_Tsimane_ps.rds')

tsimane_sprockett_sample_df = data.frame(sample_data(sprockett_tsimane_ps)) %>%
  as.data.frame() %>%
  filter(Sample_Type == 'Feces')

tsimane_basic_info %>% 
  select(sample_id, Subject_ID, Sex, Age_Years, Dyad, Community_Type, Community_Subtype, Community_Alias) %>%
  dplyr::rename(sequencing_sample_id = 1) %>%
  rowwise() %>%
  mutate(cl = strsplit(sequencing_sample_id, '_')[[1]][2],
         nu = as.numeric(strsplit(sequencing_sample_id, '_')[[1]][3])) %>%
  arrange(cl, nu) %>% 
  select(-c(cl, nu)) %>%
  filter(grepl('INFANT', sequencing_sample_id) | (grepl('ADULT', sequencing_sample_id) & Age_Years > 3)) %>%
  mutate(included_in_current_study = ifelse(sequencing_sample_id %in% tsimane_samples_included, T, F)) %>%
  write.csv('/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/250131_mgx_sequenced_tsimane_sample_metadata.csv', quote=F, row.names = F)

tsimane_basic_info %>%
  group_by(Age_Class) %>% 
  summarize(n())

actual_children = tsimane_basic_info %>% 
  filter(grepl('ADULT', sample_id) & Age_Years < 3) %>% 
  pull(sample_id)


tsimane_basic_info %>% 
  select(sample_id, Subject_ID, Sex, Age_Years, Dyad, Community_Type, Community_Subtype, Community_Alias) %>%
  dplyr::rename(sequencing_sample_id = 1) %>%
  rowwise() %>%
  mutate(cl = strsplit(sequencing_sample_id, '_')[[1]][2],
         nu = as.numeric(strsplit(sequencing_sample_id, '_')[[1]][3])) %>%
  arrange(cl, nu) %>% 
  select(-c(cl, nu)) %>%
  filter(grepl('INFANT', sequencing_sample_id) | (grepl('ADULT', sequencing_sample_id) & Age_Years > 3)) %>% 
  filter(sequencing_sample_id %in% tsimane_samples_included) %>% 
  pull(Age_Years) %>% 
  sd()

```

###  Build all study meta

```{r all_study_meta}
## Combine bin metadata from all studies
all_study_meta = rbind(uhgg_meta, hadza_meta, tsimane_meta)

# Join with GTDB taxonomy
all_mag_meta_w_gtdb = all_study_meta %>% 
  left_join(combined_gtdb_results, by=c('genome'='user_genome'))

# Score each MAG based on bin statistics
genomes_with_meta = combined_gtdb_results %>% 
  dplyr::rename(genome = user_genome, gtdb_r220_taxonomy = classification) %>%
  select(genome, gtdb_r220_taxonomy) %>%
  left_join(all_study_meta) %>%
  filter(!is.na(study)) %>%
  rowwise() %>% 
  mutate(mag_score = Completeness - 5*Contamination + 3*log10(N50) + Length/1e6) 

# Remove any bins for which GTDB can't classify a species
genomes_with_meta_no_unknowns = genomes_with_meta %>%
  filter(!grepl('s__$', gtdb_r220_taxonomy))

# Choose one MAG per species per individual
genomes_with_meta_filtered = genomes_with_meta_no_unknowns %>%
  group_by(SUBJECT_ID, gtdb_r220_taxonomy) %>%
  filter(mag_score == max(mag_score)) %>%
  filter(row_number() == 1) %>%
  ungroup() 


```

### Count species in H-T

```{r }
## Hadza
# Number Hadza subjects
genomes_with_meta_filtered %>% 
  filter(study == 'Hadza') %>% 
  pull(SUBJECT_ID) %>%
  unique() %>% 
  length()

# Number Hadza species
genomes_with_meta_filtered %>% 
  filter(study == 'Hadza') %>% 
  pull(gtdb_r220_taxonomy) %>%
  unique() %>% 
  length()

# Number Hadza MAGs
genomes_with_meta_filtered %>% 
  filter(study == 'Hadza') %>% 
  pull(genome) %>%
  unique() %>% 
  length()

## Tsimane
# Number Tsimane subjects
genomes_with_meta_filtered %>% 
  filter(study == 'Tsimane') %>% 
  pull(SUBJECT_ID) %>%
  unique() %>% 
  length()

# Number Tsimane samples
genomes_with_meta_filtered %>% 
  filter(study == 'Tsimane') %>% 
  pull(sample_id) %>%
  unique() %>% 
  length()

# Number Tsimane species
genomes_with_meta_filtered %>% 
  filter(study == 'Tsimane') %>% 
  pull(gtdb_r220_taxonomy) %>%
  unique() %>% 
  length()

# Number Tsimane MAGs
genomes_with_meta_filtered %>% 
  filter(study == 'Tsimane') %>% 
  pull(genome) %>%
  unique() %>% 
  length()

## Combined H-T
# Combined H-T species
genomes_with_meta_filtered %>% 
  filter(study == 'Tsimane' | study == 'Hadza') %>% 
  pull(gtdb_r220_taxonomy) %>%
  unique() %>% 
  length()

# Combined H-T MAGs
genomes_with_meta_filtered %>% 
  filter(study == 'Tsimane' | study == 'Hadza') %>% 
  pull(genome) %>%
  unique() %>% 
  length()

```

## Genome counts by pop

```{r genome_counts}
genome_counts_by_pop = genomes_with_meta_filtered %>% 
  group_by(gtdb_r220_taxonomy, study) %>%
  summarize(num = n()) %>%
  spread(key='study', value='num', fill=0.) %>%
  mutate(total = Hadza + Tsimane + NorthAmerica + Europe + Asia) %>%
  arrange(desc(total)) 

genome_counts_by_pop_prev_filtered = genome_counts_by_pop %>% 
  filter((Hadza >= 4 & Tsimane >= 4)) 

genome_counts_by_pop_prev_filtered %>% 
  mutate(tot2 = Hadza + Tsimane) %>% 
  pull(total) %>%
  sum()

genome_counts_by_pop_prev_filtered %>% pull(Asia) %>% sum()
genome_counts_by_pop_prev_filtered %>% filter(Asia > 0) %>% nrow()

genome_counts_by_pop_prev_filtered %>% pull(NorthAmerica) %>% sum()
genome_counts_by_pop_prev_filtered %>% filter(NorthAmerica > 0) %>% nrow()

genome_counts_by_pop_prev_filtered %>% pull(Europe) %>% sum()
genome_counts_by_pop_prev_filtered %>% filter(Europe > 0) %>% nrow()


genome_counts_by_pop_prev_filtered %>% pull(total) %>% sum()

genome_counts_by_pop_prev_filtered %>% 
  rowwise() %>% 
  mutate(phylum = strsplit(gtdb_r220_taxonomy, ';')[[1]][2]) %>% 
  pull(phylum) %>%
  unique()

genome_counts_by_pop %>%
  filter(grepl('gnavus', gtdb_r220_taxonomy))

genome_counts_by_pop_prev_filtered %>% pull(total) %>% sum()

genome_counts_by_pop %>% 
  filter(Hadza > 0 & Tsimane > 0)

genome_counts_by_pop %>% 
  filter(Hadza > 0 | Tsimane > 0) %>%
  mutate(tot2 = Hadza + Tsimane) %>%
  pull(tot2) %>%
  sum()
```


```{r }
all_pop_species = genome_counts_by_pop_prev_filtered %>% pull(gtdb_r220_taxonomy)

individuals_per_study = genomes_with_meta_filtered %>% 
  group_by(study) %>% 
  select(study, SUBJECT_ID) %>%
  distinct() %>%
  summarize(number_individuals = n())

prevalence_by_pop = genome_counts_by_pop %>%
  gather(key='study', value='number_genomes', -gtdb_r220_taxonomy, -total) %>%
  left_join(individuals_per_study, by='study') %>%
  mutate(prevalence = number_genomes / number_individuals) %>%
  select(gtdb_r220_taxonomy, study, prevalence) %>%
  spread(key='study', value='prevalence') 
  
prevalence_by_lifestyle = genome_counts_by_pop %>%
  gather(key='study', value='number_genomes', -gtdb_r220_taxonomy, -total) %>%
  left_join(individuals_per_study, by='study') %>%
  ungroup() %>%
  mutate(lifestyle = case_when(
    study %in% c('Asia', 'Europe', 'N.Am.') ~ 'Industrial',
    study %in% c('Hadza', 'Tsimane') ~ 'H-T',
    TRUE ~ NA
  )) %>%
  filter(!is.na(lifestyle)) %>%
  group_by(gtdb_r220_taxonomy, lifestyle) %>%
  summarize(total_genomes = sum(number_genomes),
            total_individuals = sum(number_individuals)) %>%
  rowwise() %>%
  mutate(lifestyle_prevalence = sum(total_genomes) / sum(total_individuals)) %>%
  select(gtdb_r220_taxonomy, lifestyle, lifestyle_prevalence) %>%
  spread(key='lifestyle', value='lifestyle_prevalence') %>%
  rowwise() %>%
  mutate(name = str_replace_all(str_replace(strsplit(gtdb_r220_taxonomy, ';')[[1]][7], 's__', ''), ' ', '_'))


prevalence_by_pop %>% 
  filter(Hadza == 0 & Tsimane > 0)

prevalence_by_pop %>% 
  filter(Hadza > 0 & Tsimane > 0)

prevalence_by_pop %>% 
  filter(Hadza == 0 & Tsimane > 0)

prevalence_by_pop %>% 
  filter((Asia < 0.01 & Europe < 0.010 & NorthAmerica < 0.01) & Tsimane > 0 & Hadza > 0 )

prevalence_by_lifestyle %>% filter(industrial == 0)
```


### Collector's curve by person

```{r }
set.seed(19760620)

series = seq(1, 85, 4)

tsimane_subjects = genomes_with_meta_filtered %>% filter(study == 'Tsimane') %>% pull(SUBJECT_ID) %>% unique()
hadza_subjects = genomes_with_meta_filtered %>% filter(study == 'Hadza') %>% pull(SUBJECT_ID) %>% unique()

rarefaction_curve_df = data.frame(n = numeric(0), study = character(0), number_species = numeric(0))
for (s in series) {
  for (i in seq(1,5)) {
    tsimane_subset = base::sample(tsimane_subjects, size=s, replace=F)
    hadza_subset = base::sample(hadza_subjects, size=s, replace=F)
    study_species_subset = genomes_with_meta_filtered %>% 
      filter(SUBJECT_ID %in% c(tsimane_subset, hadza_subset)) %>%
      group_by(study, gtdb_r220_taxonomy) %>%
      filter(row_number() == 1) %>%
      group_by(study) %>%
      summarize(number_species = n()) %>%
      ungroup() %>%
      mutate(n = s) %>%
      select(n, study, number_species)
    rarefaction_curve_df = rbind(rarefaction_curve_df, study_species_subset)
  }
}

hadza_tsimane_subject_rarefaction_plot = ggplot(rarefaction_curve_df, aes(x=n, y=number_species, color=study)) +
  geom_point() +
  geom_smooth(method='loess') +
  scale_color_brewer(palette='Dark2') +
  theme_classic() +
  xlab('Number subjects') +
  ylab('Number species')

# ggsave(filename = '/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/plots/ExtDataFigure1_rarefaction.pdf',
#        plot = hadza_tsimane_subject_rarefaction_plot,
#        width=5, height=4)

```

## Rep genome selection

```{r rep_genome_map}
all_pop_representatives = genomes_with_meta_filtered %>% 
  rowwise() %>%
  filter(gtdb_r220_taxonomy %in% all_pop_species) %>%
  mutate(mod_mag_score = ifelse(study == 'Hadza' | study == 'Tsimane', mag_score+100, mag_score)) %>%
  group_by(gtdb_r220_taxonomy) %>%
  filter(mod_mag_score == max(mod_mag_score)) 


rep_genome_map = all_pop_representatives %>% 
  mutate(species = str_replace_all(str_replace_all(str_replace(strsplit(gtdb_r220_taxonomy, ';')[[1]][7], 's__', ''), '-', '_'), ' ', '_')) %>%
  mutate(sample_name = str_replace_all(sample_id, '-', '_')) %>%
  mutate(rep_genome = paste0(species, '__', sample_name)) %>%
  ungroup() %>%
  select(species, rep_genome) %>%
  arrange(species)
  
rep_genome_map %>%
  write_tsv(file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_rep_genome_map.tsv')

```

```{r }

genomes_with_meta_filtered_with_rep_genome = genomes_with_meta_filtered %>%
  rowwise() %>%
  mutate(species = str_replace_all(str_replace_all(str_replace(strsplit(gtdb_r220_taxonomy, ';')[[1]][7], 's__', ''), '-', '_'), ' ', '_')) %>%
  left_join(rep_genome_map, by='species') %>%
  filter(!is.na(rep_genome)) %>%
  mutate(sample_name = str_replace_all(sample_id, '-', '_')) %>%
  mutate(new_fasta_name = paste0(species, '__', sample_name)) %>%
  ungroup() 


genomes_with_meta_filtered_with_rep_genome_commands = genomes_with_meta_filtered_with_rep_genome %>%
  mutate(orig_path = paste0('/home/mmcarter/user_data/Projects/VANISH/240714_snv_full_pipeline/species/', species, '/genomes/', new_fasta_name, '.fa'),
         dest_path = paste0('/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', species, '/genomes/', new_fasta_name, '.fa')) %>%
  mutate(cp_command = paste0('cp ', orig_path, ' ', dest_path),
         mkdir_command = paste0('mkdir -p /home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', species, '/genomes/ && mkdir -p /home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', species, '/output/'))

genomes_with_meta_filtered_with_rep_genome_commands %>%
  select(mkdir_command) %>%
  unique() %>%
  write.csv(file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_mkdir_species_commands.txt', col.names = F, row.names = F, quote = F)

genomes_with_meta_filtered_with_rep_genome_commands %>%
  select(cp_command) %>%
  unique() %>%
  write.csv(file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_cp_commands.txt', col.names = F, row.names = F, quote = F)

genomes_with_meta_filtered_with_rep_genome_commands %>%
  select(dest_path) %>%
  unique() %>%
  write.csv(file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_final_genome_paths.txt', col.names = F, row.names = F, quote = F)


```

#### Track down missing genomes

```{r }
hadza_tsimane_genomes = read.csv('/LAB_DATA/CURRENT/CURRENT_Metagenomics_PROJECTS/2024_Tsimane/tables/Tsimane_Hadza_MAGs_v2.csv') %>%
  select(genome, path) %>%
  rowwise() %>%
  mutate(genome = str_replace(genome, '\\.fa', '')) %>%
  select(genome, path)

uhgg_genomes = read_csv("/home/mmcarter/user_data/Projects/VANISH/comigration_paper_analysis_v2/input_data/genome_database/Carter2023_genome_database.csv") %>% 
  filter(substudy == 'SRP002163' | substudy == 'ERP004605' | substudy == 'SRP008047') %>%
  mutate(genome = str_replace(genome, '\\.fna', '')) %>%
  select(genome, path)

source_genome_paths = rbind(hadza_tsimane_genomes, uhgg_genomes)

missing_paths = read.csv('/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/missing_paths.txt') %>% pull(dest_path)

genomes_to_bring_in = genomes_with_meta_filtered_with_rep_genome_commands %>% 
  filter(dest_path %in% missing_paths) %>%
  left_join(source_genome_paths) %>%
  rowwise() %>%
  mutate(cp_command = paste0('cp ', str_replace(path, '\\.gz', ''), ' ', dest_path))

genomes_to_bring_in %>%
  filter(grepl('GUT', genome)) %>%
  mutate(gunzip_command = paste0('gunzip -c ', path, ' > ', str_replace(path, '\\.gz', ''))) %>%
  select(gunzip_command) %>%
  write.csv(file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250222_gunzip_UHGG.txt', col.names = F, row.names = F, quote = F)


genomes_to_bring_in %>% 
  select(cp_command) %>%
  unique() %>%
  write.csv(file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_cp_commands_rd2.txt', col.names = F, row.names = F, quote = F)

```

#### Input pairs

```{r }
## Do 

all_pop_species_list = rep_genome_map %>% pull(species) %>% unique() 

i = 0
for (g in all_pop_species_list) {
  i = i + 1
  print(i)
  
  one_species_genomes = genomes_with_meta_filtered_with_rep_genome %>% 
    filter(species == g)
  
  one_species_genomes %>%
      select(rep_genome, new_fasta_name) %>%
      write_tsv(file = paste0('/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', g, '/', g, '_input_pairs.tsv'),
              col_names = F)
  
}

```

####

```{r copy_coords}
all_pop_species_list %>%
  as.data.frame() %>%
  dplyr::rename(species = 1) %>%
  rowwise() %>%
  mutate(coords_cp_command = paste0('echo ', species, ' && mkdir -p /home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', species, '/output/coords_files/ && cp /home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', species, '/snv_catalog/*.coords /home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/species/', species, '/output/coords_files/')) %>%
  select(coords_cp_command) %>%
  write_tsv(file = paste0('/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_coords_copy_commands.txt'),
              col_names = F)

species_meta = genomes_with_meta_filtered_with_rep_genome %>%
  filter(new_fasta_name == rep_genome) %>%
  select(genome, gtdb_r220_taxonomy, study, sample_id, rep_genome) %>%
  # dplyr::rename(old_genome_name = genome) %>%
  left_join(genome_counts_by_pop) %>%
  dplyr::rename(total_mag_count = total) %>%
  select(rep_genome, everything())


write_tsv(species_meta,
          file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_snv_catalog_species_meta.tsv')



genomes_with_meta_filtered_with_rep_genome_for_write = genomes_with_meta_filtered_with_rep_genome %>% 
  dplyr::rename(old_genome_name = genome,
                genome = new_fasta_name,
                old_sample_name = sample_id) %>%
  mutate(s3_path = paste0('s3://sonn-current/projects/2022_Tsimane/240501_MAGs_for_GTDB/', old_genome_name, '.fa.gz')) %>%
  select(genome, gtdb_r220_taxonomy, species, rep_genome, old_genome_name, s3_path, sample_name, old_sample_name, everything()) 

write_tsv(genomes_with_meta_filtered_with_rep_genome_for_write,
          file = '/home/mmcarter/user_data/Projects/VANISH/250220_snv_full_pipeline/250220_snv_catalog_mag_metadata.tsv')
```
